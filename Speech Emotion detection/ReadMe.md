The Following project uses different approaches to detect different emotions in speech or baby emotions. 
The project makes use of multiple sound attributes such as zero crossing, chroma, spectral centroid, MFCC, RMS, etc to train the model.
The trained model can then be used to recognize and test on different human speech.
Dataset can be created using free sample from online sets.
